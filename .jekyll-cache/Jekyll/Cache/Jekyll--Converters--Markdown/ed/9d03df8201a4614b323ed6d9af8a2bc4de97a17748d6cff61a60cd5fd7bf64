I"¶F<p>Uma intelig√™ncia artificial capaz de compreender textos, do mesmo jeito que um ser humano faz, √© algo bem mais tang√≠vel hoje do que foi em um passado n√£o muito distante. Gra√ßas √† evolu√ß√£o das t√©cnicas de machine learning ao longo do tempo, hoje √© poss√≠vel ver este tipo de conceito aplicado em algumas ferramentas tecnol√≥gicas que usamos com frequ√™ncia.</p>

<p>Por exemplo, voc√™ pode nem ter percebido ainda, mas quando fazemos uma pergunta ao Google e ele vai procurar respostas em seu imenso banco de dados, um procedimento baseado em intelig√™ncia artificial que envolve interpreta√ß√£o de textos √© executado instantaneamente. O Bing, da Microsoft, tamb√©m usa este tipo de t√©cnica. At√© mesmo alguns chatbots est√£o usando isso. Na pr√°tica, √© o que nos permite fazer perguntas de uma maneira muito mais natural ao Google e contirnuarmos, ainda assim, obtendo respostas relevantes pois o texto da query n√£o precisa ser sintaticamente similar √† alguma sequ√™ncia contida no texto da resposta.</p>

<p class="image"><img src="/blog/assets/img/uma-inteligencia-artificial-que-consegue-ler-e-interpretar-textos-google.png" alt="" />
<em>A aplica√ß√£o de t√©cnicas de machine learning para interpreta√ß√£o de textos permite que fa√ßamos perguntas para o Google de uma maneira muito mais natural, como se estiv√©ssemos perguntando para um humano.</em></p>

<p>Lembra daquelas atividades que tinham no seu livro de Portugu√™s, Hist√≥ria, Geografia? Havia um texto espec√≠fico a ser lido e, nas p√°ginas seguintes, estavam as perguntinhas sobre o texto que precisavam ser respondidas (a resposta sempre estava contida em alguma parte do texto)? Pois √©, trata-se de uma tarefa trivial para qualquer humano. Para as m√°quinas, contudo, desempenhar essa mesma tarefa √© algo bastante desafiador. Mas, ent√£o, como √© que eles fazem para funcionar?</p>

<p><strong>Ao final deste post, voc√™ ter√° visto o seguinte:</strong></p>

<ol>
  <li>
    <p>Como a intelig√™ncia artificial consegue interpretar textos;</p>
  </li>
  <li>
    <p>Conjuntos de dados conhecidos;</p>
  </li>
  <li>
    <p>Alguns algoritmos interessantes (Papers e c√≥digos dos autores compartilhados no github para voc√™ tentar reproduzir os resultados);</p>
  </li>
  <li>
    <p>Poss√≠veis aplica√ß√µes pr√°ticas (um curto v√≠deo de exemplo com chatbot funcionando no Facebook Messenger);</p>
  </li>
  <li>
    <p>Fontes de estudo para leituras mais aprofundadas.</p>
  </li>
</ol>

<h2 id="como-uma-intelig√™ncia-artificial-conseguiria-tal-fa√ßanha">Como uma intelig√™ncia artificial conseguiria tal fa√ßanha?</h2>

<p>Depois de ler alguns papers sobre o assunto, me familiarizei com uma terminologia nova: <strong>Machine Reading Comprehension (MRC)</strong>. Apesar de a literatura normalmente mencionar desta forma, voc√™ pode tamb√©m chamar de Compreens√£o de Leitura de M√°quina (CLM). Estamos falando da habilidade de uma intelig√™ncia artificial fazer uso do deep learning para ler e compreender textos, tendo ainda a aptid√£o para responder perguntas baseadas em algumas passagens presentes no conte√∫do.</p>

<p>Em boa parte da literatura, notei o uso de redes neurais artificiais com base nas arquiteturas <strong>LSTM (Long-Short Term Memory)</strong> ou <strong>GRU (Gated Recurrent Unit),</strong> normalmente bidirecionais, combinados com variantes espec√≠ficas do mecanismo atencional de <strong><a href="https://arxiv.org/pdf/1409.0473.pdf">Bahdanau, et al., 2015</a></strong>. Nesse post, irei destacar alguns dos trabalhos que mais despertaram o meu interesse.</p>

<p>Por mais que voc√™ n√£o esteja familiarizado com o tema, saiba que todos os dias voc√™ experimenta isto na pr√°tica enquanto faz pesquisas no Google ou no Bing, apenas para citar um exemplo. Um tipo de tarefa que tem sido muito explorada em modelos de MRC que contam com Deep Learning √© o <a href="https://en.wikipedia.org/wiki/Question_answering">Question Answering</a>‚Äì QA (Pergunta &amp; Resposta). O pequeno v√≠deo abaixo ilustra bem este processo, que pode ter v√°rias aplica√ß√µes pr√°ticas, incluindo chatbots:</p>

<div class="video-container">
	<center><iframe width="560" height="315" src="https://www.youtube.com/embed/27As1HtqvJI" frameborder="0" allowfullscreen=""></iframe></center>
</div>

<p>Muito embora n√£o pare√ßa, este tema n√£o √© nada novo. Por volta do ano 2000, isto j√° tinha relev√¢ncia quando <a href="http://www.aclweb.org/anthology/W00-1316">Ng et al.</a> desenvolveu um modelo de machine learning baseado em regress√£o log√≠stica para compreens√£o de leitura de m√°quina. Usado para responder perguntas aleat√≥rias ap√≥s ser exposto a qualquer texto in√©dito, o modelo foi o primeiro a mostrar que o uso de machine learning era capaz de alcan√ßar resultados competitivos em MRC.</p>

<h2 id="o-surgimento-de-datasets-mais-precisos">O surgimento de Datasets mais precisos</h2>

<p>Avan√ßos mais significativos neste t√≥pico passaram a ocorrer muito recentemente, principalmente com o uso mais abrangente das redes neurais artificiais e tamb√©m devido √† maior disponibilidade de dados para usar como treino. N√£o apenas isso, mas tamb√©m devido √† disponibilidade de datasets mais realistas e precisos. O resultado disto √© que o MRC passou a ser um dos t√≥picos mais ‚Äúquentes‚Äù na √°rea de Processamento de Linguagem Natural (PLN).</p>

<p><a href="https://arxiv.org/pdf/1606.05250.pdf">Rajpurkar et al. (2016)</a> disponibilizou publicamente <a href="https://rajpurkar.github.io/SQuAD-explorer/">o seu dataset</a> <strong>S</strong>tanford <strong>Q</strong>uestion <strong>A</strong>nswering <strong>D</strong>ataset (<strong>SQuAD</strong>), que viabilizou o desenvolvimento de diversos modelos interessantes. Trata-se de um dataset composto por <strong>100.000+</strong> perguntas elaboradas por humanos com base em um conjunto de artigos da Wikip√©dia. A resposta para cada pergunta √© um segmento de texto destacado manualmente a partir de alguma passagem presente no artigo. Recentemente, foi libearada a vers√£o 2.0 do dataset. O SQuAD2.0 testa a capacidade de um modelo n√£o apenas responder √†s perguntas no processo de interpreta√ß√£o, mas tamb√©m se abster de responder quando for feita uma pergunta que n√£o pode ser respondida com base no conte√∫do fornecido.</p>

<p class="image"><img src="https://cdn-images-1.medium.com/max/2000/1*RXS4n7ykoPKzG8S-Rlgfrg.png" alt="Exemplo de pares de pergunta-resposta presentes no dataset SQuAD. Cada uma das respostas √© um segmento de texto da passagem. Cr√©ditos: Rajpurkar et al. (2016)" /><em>Exemplo de pares de pergunta-resposta presentes no dataset SQuAD. Cada uma das respostas √© um segmento de texto da passagem. Cr√©ditos: Rajpurkar et al. (2016)</em></p>

<p>Algum tempo depois, <a href="https://arxiv.org/pdf/1611.09268v2.pdf">Nguyen et al. (2016)</a> disponibilizou o <a href="http://www.msmarco.org/">dataset</a> <strong>MS MARCO</strong>: <strong>MA</strong>chine <strong>R</strong>eading <strong>CO</strong>mprehension Dataset. Refere-se √† um conjunto de dados de alto padr√£o, cuidadosamente preparado com base em documentos coletados a partir do √≠ndice do buscador Bing. As respostas para as perguntas neste dataset tamb√©m foram pontuadas por humanos, tornando este conjunto de dados t√£o preciso e real quanto o SQuAD, ou al√©m.</p>

<h1 id="alguns-trabalhos-interessantes">Alguns trabalhos interessantes</h1>

<h2 id="bidaf--bi-directional-attention-flow-network">BiDAF ‚Äî Bi-Directional Attention Flow network</h2>

<p>Diversos trabalhos interessantes surgiram diante da disponibilidade destes conjuntos de dados. <a href="https://arxiv.org/abs/1611.01603">Seo et al., (2017)</a> prop√µe uma arquitetura hier√°rquica em seis camadas, a qual conta com um mecanismo antencional <a href="https://arxiv.org/pdf/1409.0473.pdf">Bahdanau, et al., 2015</a> operando ao longo de um fluxo bidirecional. O modelo, que foi testado na solu√ß√£o de um problema de QA, utiliza uma variante do mecanismo atencional para obter uma representa√ß√£o do contexto referente √† passagem textual, a qual est√° ligada a uma pergunta espec√≠fica. Este fluxo ocorrendo em ambas as dire√ß√µes √© justificado pelo ganho de informa√ß√µes que ele proporciona, ao obter dados contextuais em duas m√£os.</p>

<p>No <strong>BiDAF</strong>, o contexto da passagem √© observado e computado a partir de uma dada pergunta (Context2Query), e tamb√©m no sentido contr√°rio (Query2Context). A figura abaixo ilustra bem este processo:</p>

<p><img src="https://cdn-images-1.medium.com/max/2000/1*r-LvP2My-IHymbzPa4r1hw.png" alt="Uma ilustra√ß√£o do fluxo atencional bi-direcional. Cr√©ditos: **Seo et al., 2017**" /><em>Uma ilustra√ß√£o do fluxo atencional bi-direcional. Cr√©ditos: <strong>Seo et al., 2017</strong></em></p>

<p>Voc√™ pode visualizar o modelo em funcionamento <a href="http://allgood.cs.washington.edu:1995/">por meio deste link</a>. Caso queira reproduzir os resultados, os autores disponibilizaram o <a href="https://github.com/allenai/bi-att-flow">c√≥digo no github</a>.</p>

<h2 id="match-lstm">match-LSTM</h2>

<p>Um outro algoritmo bem legal √© o de <a href="https://arxiv.org/pdf/1608.07905.pdf">Wang &amp; Jiang (2016a)</a>, o qual baseia-se no uso combinado de duas arquiteturas: <strong>match-LSTM</strong> e <strong>Ptr-Net</strong>. Funciona com base no seguinte princ√≠pio: Uma vez que √© dada uma passagem de texto e uma pergunta relacionada com esta passagem, o objetivo √© usar a referida combina√ß√£o para identificar uma sequ√™ncia dentro da passagem que corresponda √† pergunta.</p>

<p>A <strong>match-LSTM</strong> percorre todos os tokens da passagem sequencialmente, computando um conjunto de pesos atencionais com o objetivo de medir o grau de relacionamento entre o <em>i-√©simo</em> token da passagem e o <em>j-√©simo</em> token da pergunta. Em seguida, estas duas partes s√£o combinada em um vetor que √© dado como entrada para uma LSTM unidirecional. A <strong>match-LSTM</strong> opera em duas dire√ß√µes com o objetivo de obter o contexto de cada token da passagem em ambos os sentidos da leitura (esquerda-direita/direita-esquerda).</p>

<p>A <strong>Ptr-Net</strong>, que representa a sa√≠da do modelo<strong>,</strong> fica encarregada de predizer onde come√ßa e onde termina a sequ√™ncia que corresponde √† resposta para a pergunta. Deste modo, ela apenas precisa selecionar dois tokens a partir da passagem, a=(as,ae). Neste caso, as e ae representam o in√≠cio e o fim da sequ√™ncia que corresponde √† resposta, respectivamente. Eles chamaram este m√©todo de <strong>Boundary Model</strong>. A figura abaixo ilustra esta arquitetura:</p>

<p class="image"><img src="https://cdn-images-1.medium.com/max/2000/1*Xf5JNJV7HiZE3ix6GOed2Q.png" alt="a match-LSTM opera em duas dire√ß√µes, passando a sa√≠da para a camada Ptr, que tem o objetivo de predizer as fronteiras da sequ√™ncia de resposta. Cr√©ditos: **Wang &amp; Jiang (2016a)**" /><em>a match-LSTM opera em duas dire√ß√µes, passando a sa√≠da para a camada Ptr, que tem o objetivo de predizer as fronteiras da sequ√™ncia de resposta. Cr√©ditos: <strong>Wang &amp; Jiang (2016a)</strong></em></p>

<p>No mesmo trabalho, os autores tamb√©m usaram uma outra variante do modelo, que n√£o mencionei aqui, mas voc√™ pode conferir no paper que j√° foi linkado. Caso queira testar o c√≥digo e tentar reproduzir os resultados, ele est√° dispon√≠vel <a href="https://github.com/shuohangwang/SeqMatchSeq">neste link do github</a>.</p>

<h2 id="reading-wikipedia-to-answer-open-domain-questions">Reading Wikipedia to Answer Open-Domain Questions</h2>

<p>Tamb√©m despertou a minha aten√ß√£o o trabalho de <a href="https://arxiv.org/pdf/1704.00051.pdf">Chen et al., (2017)</a>, o qual consiste num modelo que opera em larga escala. Ele √© voltado para trazer respostas a perguntas em dom√≠nio aberto, usando a Wikip√©dia como √∫nica base de conhecimento. A arquitetura combina um componente de buscas (<strong>Document Retriever</strong>), baseado na medida TF-IDF, com uma rede neural LSTM de m√∫ltiplas camadas (<strong>Document Reader</strong>), a qual √© treinada para encontrar respostas em m√∫ltiplos par√°grafos de artigos da Wikip√©dia. Estes dois componentes trabalham da seguinte maneira:</p>

<ol>
  <li>
    <p><strong>Document Retriever</strong> ‚Äî Um componente de buscas (n√£o baseado em machine learning) √© usado para retornar um subconjunto de artigos relevantes, com grandes chances de conter a resposta de uma pergunta. Para qualquer pergunta que √© feita ao modelo, apenas 5 artigos da Wikip√©dia s√£o retornados. A pergunta e os artigos obtidos s√£o comparados usando a medida TF-IDF.;</p>
  </li>
  <li>
    <p><strong>Document Reader</strong> ‚Äî Uma rede neural recorrente LSTM bidirecional recebe o retorno do primeiro componente do modelo e tenta identificar a resposta esperada a partir deste conte√∫do. A rede neural agrega informa√ß√£o a partir de diferentes par√°grafos para compor a resposta final.</p>
  </li>
</ol>

<p class="image"><img src="https://cdn-images-1.medium.com/max/2562/1*id4F3D0yOO74FNydnRqMrg.png" alt="Uma ilustra√ß√£o do modelo QA de [**Chen et al., (2017)**](https://arxiv.org/pdf/1704.00051.pdf)" /> <em>Uma ilustra√ß√£o do modelo QA de <a href="https://arxiv.org/pdf/1704.00051.pdf"><strong>Chen et al., (2017)</strong></a></em></p>

<p>Para compor a base de conhecimentos usada para responder √†s perguntas de dom√≠nio aberto, os autores utilizaram um dump de todos os artigos da Wikip√©dia em ingl√™s datado de 2016. Os autores tamb√©m utilizaram o dataset SQuAD, para treinar o componente <strong>Document Reader</strong>.</p>

<blockquote>
  <p><em>‚ÄúN√≥s estamos interessados em obter um sistema simples e completo, capaz de responder a qualquer pergunta usando a Wikip√©dia</em> ‚Äú ‚Äî <a href="https://arxiv.org/pdf/1704.00051.pdf">Chen et al., (2017)</a></p>
</blockquote>

<p>Caso voc√™ esteja interessado no c√≥digo para reproduzir os resultados do paper, os autores o <a href="https://github.com/facebookresearch/DrQA">disponibilizaram no github</a>.</p>

<h2 id="poss√≠veis-aplica√ß√µes">Poss√≠veis aplica√ß√µes</h2>

<p>Como voc√™ j√° deve ter notado, modelos baseados em Machine Reading Comprehension t√™m mostrado uma incr√≠vel capacidade para entendimento da linguagem natural, considerando se tratar de uma tarefa que √© bastante desafiadora at√© mesmo para uma intelig√™ncia artificial mais avan√ßada. Este potencial abre portas para diversas aplica√ß√µes pr√°ticas poss√≠veis. Como mencionado no in√≠cio do post, h√° aplica√ß√µes em mecanismos de buscas e chatbots, mas s√£o apenas dois exemplos e pode haver bem mais.</p>

<p>Voc√™ poderia, por exemplo, usar isto para desenvolver um chatbot e disponibiliz√°-lo na p√°gina de vendas de um produto (o cliente poderia perguntar: <em>Qual √© a configura√ß√£o de mem√≥ria deste notebook?</em>) ou na p√°gina FAQ do seu site. Assistentes virtuais que funcionam em sistemas de EAD tamb√©m podem se beneficiar deste tipo de tecnologia.</p>

<p>Para que voc√™ possa visualizar melhor, achei que seria interessante exemplificar por meio de um pequeno v√≠deo, ilustrando uma situa√ß√£o real. Digamos que seu chatbot seja respons√°vel por tirar d√∫vidas dos visitantes em uma p√°gina de produto. Ent√£o, ele normalmente teria como base de conhecimento as especifica√ß√µes do produto, o que na literatura j√° vista neste post √© normalmente referenciado como <em>passagem de texto</em>. Veja um exemplo abaixo:</p>
<blockquote>
  <p>Informa√ß√µes sobre o produto podem ser obtidas aqui. O Moto G6 Plus possui sensor de impress√£o digital multifun√ß√£o. Com ele, voc√™ n√£o precisa mais digitar senha quando quiser acessar os aplicativos do seu smartphone. Basta usar o sensor de impress√£o digital multifun√ß√£o que, al√©m de desbloquear ou bloquear seu aparelho, pode ser utilizado como bot√£o de navega√ß√£o, para que a tela tenha um maior aproveitamento do espa√ßo. O Moto G6 Plus tem Processador Qualcomm Snapdragon 630 Octa-Core 2,2 GHz com recursos gr√°ficos avan√ßados, para que voc√™ execute aplicativos e navegue na web. A bateria de 3200 mAh do Moto G6 Plus tem capacidade suficiente para o dia inteiro. Para isso, ela √© turbinada pelo super carregador TurboPower, que fornece at√© 6 horas de uso com apenas 15 minutos de carregamento. Voc√™ pode pagar com cart√µes VISA e MASTER.</p>
</blockquote>

<p>Neste caso, sempre que algu√©m fizer qualquer pergunta relacionada √† passagem acima, seu chatbot conseguir√° responder. Veja, no v√≠deo abaixo, o exemplo de um chatbot que aplica este princ√≠pio, funcionando no Facebook Messenger:</p>

<div class="video-container">
	<center><iframe width="560" height="315" src="https://www.youtube.com/embed/isI9UuuBcbs" frameborder="0" allowfullscreen=""></iframe></center>
</div>

<p>Claro, ainda h√° muito espa√ßo para melhorar. Toda semana, praticamente, algu√©m publica um paper com uma arquitetura nova que supera os resultados obtidos em trabalhos anteriores. √â interessante ficar de olho e sempre tentar reproduzir os resultados depois de ler estes papers, compreender a arquitetura dos modelos e tentar rodar os c√≥digos que quase sempre s√£o disponibilizados pelos autores no github.</p>

<h2 id="leitura-aprofundada">Leitura aprofundada</h2>

<p>Para uma leitura mais aprofundada, consulte os seguintes papers:</p>

<p><a href="https://arxiv.org/pdf/1704.00051.pdf">Reading Wikipedia to Answer Open-Domain Questions</a>, 2017</p>

<p><a href="https://arxiv.org/pdf/1608.07905.pdf">Machine Comprehension Using match-LSTM and Answer Pointer</a>, 2016</p>

<p><a href="https://arxiv.org/pdf/1611.01603.pdf">Bidirectional Attention Flow for Machine Comprehension</a>, 2016</p>

<p><a href="https://arxiv.org/pdf/1409.0473.pdf">Neural Machine Translation By Jointly Learning To Align and Translate</a>, 2014</p>

<p><a href="https://arxiv.org/pdf/1606.05250.pdf">SQuAD: 100,000+ Questions for Machine Comprehension of Text</a>, 2016</p>

<p><a href="https://arxiv.org/pdf/1611.09268v2.pdf">MS MARCO: A Human Generated MAchine Reading COmprehension Dataset</a>, 2016</p>
:ET