I"pG<div class="video-container">
	<center><iframe width="560" height="315" src="https://www.youtube.com/embed/uJpU0rYUokM" frameborder="0" allowfullscreen=""></iframe></center>
</div>

<p>A classificação de textos é uma das mais importantes aplicações do processamento de linguagem natural hoje em dia. É o que possibilita diversas interações entre usuários uma infinidade de ferramentas computacionais disponíveis hoje. Entre estas ferramentas, estão os <em>chatbots</em>. Neste post, você verá como classificar textos com machine learning e a linguagem Python. Você vai precisar do framework <a href="http://scikit-learn.org/stable/">Scikit-Learn</a> instalado na sua máquina. Eu sugiro que instale a ferramenta <a href="https://anaconda.org/">Anaconda</a>, com a qual é muito fácil instalar diversas outras ferramentas do ecossistema python, incluindo o Scikit-Learn. Eu vou assumir que você já conheça a linguagem Python e já possui um entendimento básico do framework acima mencionado. Este post acompanha um vídeo, cujo link está no final. Você também poderá baixar o <a href="https://github.com/luisfredgs/machine-learning-text-classification">código no github</a>.</p>

<h2 id="o-dataset">O dataset</h2>

<p>O “20 Newsgroups” é um conjunto de dados disponível publicamente para uso em pesquisas. Contém aproximadamente 20k documentos, divididos em cerca de 20 categorias. É um data set popular e conhecido pelo seu uso tarefas de classificação de textos em machine learning. Os conteúdos do data set estão separados por categoria e algumas destas categorias são muito próximas: <strong><em>comp.sys.ibm.pc.hardware</em></strong> e <strong><em>comp.sys.mac.hardware</em></strong>. Há outras categorias que não possuem quaisquer semelhanças: <strong><em>rec.autos</em></strong> e <strong><em>talk.politics.misc</em></strong>. Nosso objetivo aqui é obter um modelo capaz de classificar textos em algumas destas categorias.</p>

<p class="image"><img src="https://cdn-images-1.medium.com/max/2000/0*ry5TWGyyiwFDw7O9.png" alt="O dataset 20 Newsgroups" /><em>O dataset 20 Newsgroups</em></p>

<h3 id="importando-nossas-classes-o-dataset-e-demais-funções">Importando nossas classes, o dataset e demais funções</h3>

<p>Nós contaremos com dois algoritmos diferentes para gerar o nosso modelo: Um <strong>SVM (por meio do estimador SGDClassifier)</strong> e uma rede neural Perceptron Multicamadas, que nada mais é do que <strong>uma rede neural feed-forward</strong>. O objetivo é experimentar um estimador de cada vez, para averiguar a performance de cada um no conjunto de dados validação. Em seguida, usaremos nosso modelo para fazer predições em dados que não foram vistos no conjunto de treino. No vídeo que acompanha este post, eu experimentei os dois estimadores e foi possível notar que a rede neural se saiu melhor. Neste post, entretanto, você verá que eu deixei comentada a linha que permite treinar o modelo via SGDClassifier, usando apenas o MPLClassifier. Mas basta que você remova o comentário no código, para que possa testar com ambos os estimadores, um de cada vez, como fiz durante o vídeo.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">fetch_20newsgroups</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">TfidfVectorizer</span>

<span class="c1"># um classificador linear que utiliza o Gradiente Descendente Estocástico como método de treino. 
# Por padrão, utiliza o estimador SVM.
</span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">SGDClassifier</span>
<span class="c1"># Uma rede neural Perceptron Multicamadas
</span><span class="kn">from</span> <span class="nn">sklearn.neural_network</span> <span class="kn">import</span> <span class="n">MLPClassifier</span>

<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">metrics</span>

<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span></code></pre></figure>

<h2 id="limitando-a-quantidade-de-categorias-e-obtendo-os-dados-de-treino">Limitando a quantidade de categorias e obtendo os dados de treino</h2>

<p>Apenas por uma questão de agilidade, iremos reduzir a quantidade de dados a serem processados. Conseguiremos isto ao limitar o número de categorias em apenas duas. Nosso modelo classificará textos na área de <strong><em>política</em></strong> e <strong><em>automobilismo</em></strong>. Você pode escolher qualquer uma das categorias ilustradas na imagem anterior, ou utilizar todas elas :-).</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">categories</span> <span class="o">=</span> <span class="p">[</span><span class="s">'talk.politics.misc'</span><span class="p">,</span> <span class="s">'rec.autos'</span><span class="p">]</span>
<span class="n">twenty_train</span> <span class="o">=</span> <span class="n">fetch_20newsgroups</span><span class="p">(</span><span class="n">subset</span><span class="o">=</span><span class="s">'train'</span><span class="p">,</span><span class="n">categories</span><span class="o">=</span><span class="n">categories</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span></code></pre></figure>

<h2 id="treinando-o-classificador">Treinando o classificador</h2>

<p>Dados textuais representam valores discretos, e nosso classificador “só entende números”. Nós precisamos converter os dados brutos, que estão em formato de texto, para uma formato numérico. Isto deve acontecer antes de podermos passar os dados para o nosso classificador.</p>

<p class="image">É preciso levar em conta, ainda, que algumas palavras no corpus de treino serão muito presentes, como é o caso de preposições e artigos. Estas palavras tendem a se repetir em todos os documentos e não costumam carregar informação muito significativa para o que precisamos aqui. Nós utilizaremos a medidade TF-IDF para limitar a importância destas palavras que se repetem muito ao longo dos documentos, de maneira que elas não causem mais influência do que o necessário. TF-IDF significa <strong><em>frequência do termo–inverso da frequência nos documentos</em></strong> e se baseia na seguinte formula.</p>
<p><img src="https://cdn-images-1.medium.com/max/2608/1*V9ac4hLVyms79jl65Ym_Bw.png" alt="" /></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">vectorizer</span> <span class="o">=</span> <span class="n">TfidfVectorizer</span><span class="p">()</span>
<span class="n">X_train_tfidf_vectorize</span> <span class="o">=</span> <span class="n">vectorizer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">twenty_train</span><span class="o">.</span><span class="n">data</span><span class="p">)</span></code></pre></figure>

<p>Abaixo, nós iniciamos o processo de treino do nosso classificador, o que corresponderia a ajustar o estimador aos dados que nós temos. Iremos usar o <strong><em>MLPClassifier</em></strong>, mas deixei o <strong><em>SGDClassifier</em></strong>comentado, caso queira testar este estimador também. O <strong><em>MLPClassifier</em></strong> é, na verdade, uma rede neural Feed-Foward.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># Aqui nós treinamos o classificador
#clf = SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, random_state=42, max_iter=5, tol=None)
</span><span class="n">clf</span> <span class="o">=</span> <span class="n">MLPClassifier</span><span class="p">(</span><span class="n">solver</span><span class="o">=</span><span class="s">'lbfgs'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">,</span> <span class="n">hidden_layer_sizes</span><span class="o">=</span><span class="p">(</span><span class="mi">70</span><span class="p">,</span> <span class="p">),</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_tfidf_vectorize</span><span class="p">,</span> <span class="n">twenty_train</span><span class="o">.</span><span class="n">target</span><span class="p">)</span></code></pre></figure>

<p>O comando <strong><em>clf.fit()</em></strong> é responsável por treinar o nosso modelo.</p>

<h2 id="avaliando-a-performance">Avaliando a performance</h2>

<p>Agora, nós precisamos avaliar a performance do nosso modelo para sabermos o quanto ele aprendeu com os dados de treino. Para isto, utilizaremos um subconjunto dos dados, os dados que separamos para os testes.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">twenty_test</span> <span class="o">=</span> <span class="n">fetch_20newsgroups</span><span class="p">(</span><span class="n">subset</span><span class="o">=</span><span class="s">'test'</span><span class="p">,</span> <span class="n">categories</span><span class="o">=</span><span class="n">categories</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">docs_test</span> <span class="o">=</span> <span class="n">twenty_test</span><span class="o">.</span><span class="n">data</span>

<span class="n">vect_transform</span> <span class="o">=</span> <span class="n">vectorizer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">docs_test</span><span class="p">)</span>
<span class="n">predicted</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">vect_transform</span><span class="p">)</span>


<span class="k">print</span><span class="p">(</span><span class="n">metrics</span><span class="o">.</span><span class="n">classification_report</span><span class="p">(</span><span class="n">twenty_test</span><span class="o">.</span><span class="n">target</span><span class="p">,</span> <span class="n">predicted</span><span class="p">,</span><span class="n">target_names</span><span class="o">=</span><span class="n">twenty_test</span><span class="o">.</span><span class="n">target_names</span><span class="p">))</span>

<span class="k">print</span><span class="p">(</span><span class="n">clf</span><span class="o">.</span><span class="n">classes_</span><span class="p">)</span></code></pre></figure>

<p>Em meus testes, eu obtive o seguinte resultado:</p>

<p class="image zoom"><img src="https://cdn-images-1.medium.com/max/2000/1*aVNagC-IWUfDYp-Qk0iuKQ.png" alt="*Avaliando a performance do modelo com algumas medidas de avaliação, como 'precision', 'medida-f1' e 'recall'*" /><em>Avaliando a performance do modelo com algumas medidas de avaliação, como ‘precision’, ‘medida-f1’ e ‘recall’</em></p>

<h2 id="matriz-de-confusão">Matriz de Confusão</h2>

<p>Usada para visualizar a performance de um classificador. As linhas da matriz indicam as classes que se espera obter corretamente por meio do modelo. As colunas indicam as classes que foram obtidas efetivamente. Cada célula contém o número de predições feitas pelo classificador, relativas ao contexto daquela célula específica.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">confusion_matrix</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">twenty_test</span><span class="o">.</span><span class="n">target</span><span class="p">,</span> <span class="n">predicted</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">matshow</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s">"Matriz de confusão"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">"Classificações corretas"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"Classificações obtidas"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span></code></pre></figure>

<p>A saída do código acima será algo como a seguinte figura:</p>

<p class="image"><img src="https://cdn-images-1.medium.com/max/2000/1*zjeRqyzr0MxzFhC4NI2row.png" alt="um exemplo de uma matriz de confusão para uma classificador binário" /><em>um exemplo de uma matriz de confusão para uma classificador binário</em></p>

<h2 id="fazendo-predições-em-dados-novos">Fazendo predições em dados novos</h2>

<p>Agora, chega a parte mais interessante, que é usar o nosso modelo para classificar textos que não estão presentes no conjunto de dados de treino, ou seja, textos que o modelo ainda “não viu”. Considerando que o dataset é composto de textos apenas em inglês, então, o nosso modelo não vai “entender outra língua”. É por isso que iremos testar o nosso modelo com textos em inglês:</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">docs_new</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s">'Wednesday morning, the legal team had appeared to turn back toward more discreet lawyering, with the announcement that Washington trial lawyer Emmet Flood would join the team inside the White House.'</span><span class="p">,</span>
    <span class="s">'By the time Rolls-Royce unveiled its one-of-a-kind Serenity Phantom at the 2015 Geneva Motor Show.'</span>
<span class="p">]</span>

<span class="n">X_new_tfidf_vectorize</span> <span class="o">=</span> <span class="n">vectorizer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">docs_new</span><span class="p">)</span>

<span class="n">predicted</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_new_tfidf_vectorize</span><span class="p">)</span>

<span class="k">for</span> <span class="n">doc</span><span class="p">,</span> <span class="n">category</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">docs_new</span><span class="p">,</span> <span class="n">predicted</span><span class="p">):</span>
	<span class="k">print</span><span class="p">(</span><span class="s">'</span><span class="si">%</span><span class="s">r =&gt; </span><span class="si">%</span><span class="s">s'</span> <span class="o">%</span> <span class="p">(</span><span class="n">doc</span><span class="p">,</span> <span class="n">twenty_train</span><span class="o">.</span><span class="n">target_names</span><span class="p">[</span><span class="n">category</span><span class="p">]))</span></code></pre></figure>

<p>O código acima irá exibir cada texto apresentado ao modelo por meio do array, com a categoria ao lado. Por exemplo, no meu experimento, eu obtive o seguinte retorno:</p>

<p class="image"><img src="https://cdn-images-1.medium.com/max/2000/1*Ypu6vhfHfcrc_8XoT4ngXA.png" alt="Predição obtida por meio do modelo classificador de textos" /><em>Predição obtida por meio do modelo classificador de textos</em></p>

<p>Para mais detalhes e maiores explicações, veja o vídeo que está no início deste post. Aproveita e participa do<a href="https://join.slack.com/t/falandosobreia/shared_invite/enQtMzI4NjkzMjI1NjgyLTZlN2VhN2VkMzc2MjYxNDYzOWZkNWEzZWQ5MmM5NDA2NWFmYzFlNTVjMmUxMzQyMGYwOTk4Y2JhNTI0ZjNmYzg"> grupo que criei no Slack</a>, para tratar de assuntos diversos envolvendo machine learning e inteligência artificial.</p>

<p>E se você quiser saber um pouco mais sobre machine learning, veja o vídeo da live que apresentei recentemente, onde comentei sobre alguns aspectos teóricos desta que está sendo a profissão mais cobiçada da atualidade:</p>

<div class="video-container">
	<center><iframe width="560" height="315" src="https://www.youtube.com/embed/WgUrONLhons" frameborder="0" allowfullscreen=""></iframe></center>
</div>

<h2 id="leia-também">Leia também</h2>

<ol>
  <li>
    <p><a href="/livros/7-livros-essenciais-para-aprender-machine-learning">7 livros essenciais para aprender machine learning</a></p>
  </li>
  <li>
    <p><a href="/deep-learning/analise-de-sentimentos-usando-redes-neurais">Análise de sentimentos com redes neurais recorrentes LSTM</a></p>
  </li>
  <li>
    <p><a href="/deep-learning/reconhecimento-de-entidades-nomeadas-ner-e-aplicacoes">Reconhecimento de Entidades Nomeadas (NER) — O que é? Quais são as aplicações?</a></p>
  </li>
</ol>
:ET